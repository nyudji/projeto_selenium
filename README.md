<div align="center">
  <h1>Projeto Selenium</h1>
  
</div>
<br>
Projeto Selenium, webscraping de produtos da Farfetch, feito ETL com Pandas e PySpark, salvando ofertas tratadas em csv e parquet, e com painel e dash em Streamlit.


## Scrapping
- Entra no site da Farfetch
- Entra na seções de promoções de jaquetas
- Pega os produtos
- Realiza o Tratamento
- Salva em CSV e Parquet os dados brutos e tratados
  
<div align="center">
    <img src="https://github.com/user-attachments/assets/3db4877a-0fc8-4724-b9c0-bbc64101d33a" alt="image">
</div>

 ## Dados
- Produto
- Marca
- Preço Original
- Preço com desconto

 ## Dados tratados
- Data e Hora
- Desconto
- Categoria Preço
- Classificação Produto
- Acima ou abaixo do preço médio

## Funções
- Login Streamlit
- Scraping de produtos
- ETL com Spark e Pandas
- Dash e Painel com Streamlit
- CSV e Parquet
  
<div align="center">
    <img src="https://github.com/user-attachments/assets/372b5a2e-84b3-4521-afa1-9c2b99dd9b71" alt="image">
</div>

 ## Ferramentas
- Python
- Selenium
- Streamlit
- Pandas
- Spark
   
## Implementações futuras
- Integração com Postgre
- Relatório com IA


## Requirements
- Python 3.12
- `streamlit` 
- `pandas`
- `selenium` 
- `pyspark` 

<div align="center">
<h1>Utilizando PySpark no Windows 11</h1>
Baixar: spark 3.5.0 > ; hadoop 3.3.6 ; winutils 3.3.6 ; jdk 11 >
Extrair o spark no c:/spark, colocar o hadoop no c:/spark/hadoop/ , o winutils dentro do bin do hadoop e configurar as variaveis de ambiente do Windows, JAVA_HOME, SPARK_HOME, PYSPARK_HOME, HADOOP_HOME.
</div>
